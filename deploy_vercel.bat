@echo off
echo ğŸš€ Deploying Swiggy Delivery Time Predictor to Vercel
echo.
echo ğŸ“‹ Deployment Configuration:
echo    - App: app_vercel.py (Hybrid Model System)
echo    - Requirements: requirements_vercel.txt (Minimal dependencies)
echo    - Models: Excluded from deployment (uses lightweight algorithm)
echo    - Size: Under 50MB limit
echo.

echo ğŸ”§ Checking files...
if exist "app_vercel.py" (
    echo âœ… app_vercel.py found
) else (
    echo âŒ app_vercel.py not found
    pause
    exit /b 1
)

if exist "requirements_vercel.txt" (
    echo âœ… requirements_vercel.txt found
) else (
    echo âŒ requirements_vercel.txt not found
    pause
    exit /b 1
)

if exist "hybrid_model.py" (
    echo âœ… hybrid_model.py found
) else (
    echo âŒ hybrid_model.py not found
    pause
    exit /b 1
)

if exist "templates" (
    echo âœ… templates folder found
) else (
    echo âŒ templates folder not found
    pause
    exit /b 1
)

echo.
echo ğŸ“¦ What will be deployed:
echo    âœ… FastAPI app with hybrid model system
echo    âœ… Lightweight prediction algorithm
echo    âœ… Templates and static files
echo    âœ… Data cleaning functions (minimal)
echo    âŒ ML models (excluded - too large)
echo    âŒ Heavy dependencies (excluded)
echo.

echo ğŸ¯ Expected behavior:
echo    - Local: Uses full ML model (if models exist)
echo    - Vercel: Uses lightweight algorithm automatically
echo    - Same UI and functionality
echo    - Fast deployment and response times
echo.

echo ğŸš€ Ready to deploy! Run: vercel --prod
echo ğŸ“ Or visit: https://vercel.com/dashboard
echo.
pause
