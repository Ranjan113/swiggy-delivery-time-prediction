@echo off
echo ğŸš€ Deploying Swiggy Delivery Time Predictor to Vercel
echo.
echo ğŸ“‹ Deployment Configuration:
echo    - App: api/index.py (Lightweight Algorithm)
echo    - Requirements: requirements.txt (Minimal dependencies)
echo    - Models: Excluded from deployment (uses lightweight algorithm)
echo    - Size: Under 50MB limit
echo.

echo ğŸ”§ Checking files...
if exist "api\index.py" (
    echo âœ… api/index.py found
) else (
    echo âŒ api/index.py not found
    pause
    exit /b 1
)

if exist "requirements.txt" (
    echo âœ… requirements.txt found
) else (
    echo âŒ requirements.txt not found
    pause
    exit /b 1
)

if exist "templates" (
    echo âœ… templates directory found
) else (
    echo âŒ templates directory not found
    pause
    exit /b 1
)

if exist "vercel.json" (
    echo âœ… vercel.json found
) else (
    echo âŒ vercel.json not found
    pause
    exit /b 1
)

echo.
echo ğŸ“¦ What will be deployed:
echo    âœ… FastAPI app with hybrid model system
echo    âœ… Lightweight prediction algorithm
echo    âœ… Templates and static files
echo    âœ… Data cleaning functions (minimal)
echo    âŒ ML models (excluded - too large)
echo    âŒ Heavy dependencies (excluded)
echo.

echo ğŸ¯ Expected behavior:
echo    - Local: Uses full ML model (if models exist)
echo    - Vercel: Uses lightweight algorithm automatically
echo    - Same UI and functionality
echo    - Fast deployment and response times
echo.

echo ğŸš€ Ready to deploy! Run: vercel --prod
echo ğŸ“ Or visit: https://vercel.com/dashboard
echo.
pause
